{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP7DcuY4uPQNrM0w0l+s47B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PaoloMadda01/Projects-with-Google-Colab/blob/main/CODEF_TF_Modello.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizzo un modello personale (GITHUB)"
      ],
      "metadata": {
        "id": "3INWFOUONS09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VR74gKosWSU",
        "outputId": "5bf8a288-5aa4-4c53-e732-add1833adf26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.1/612.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.21.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import VGG19\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_hub as hub\n",
        "import cv2\n",
        "import numpy as np\n",
        "import imageio\n",
        "import time\n",
        "from PIL import Image\n",
        "from google.colab import files\n",
        "import tensorflow as tf\n",
        "from google.colab import files\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2sSykPzXLKR",
        "outputId": "5483cf6c-c5ec-414d-fa51-7964d68909ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Carica l'immagine dal tuo computer\n",
        "uploaded = files.upload()\n",
        "style_image_path = list(uploaded.keys())[0]\n",
        "\n",
        "# Apri l'immagine usando PIL\n",
        "style_image_pil = Image.open(style_image_path)\n",
        "\n",
        "# Converti l'immagine PIL in un array NumPy\n",
        "style_image_np = np.array(style_image_pil)\n",
        "\n",
        "# Normalizza l'immagine se necessario (ad esempio, scala i valori dei pixel a [0, 1])\n",
        "# Questo passaggio potrebbe non essere necessario a seconda del tuo modello\n",
        "style_image_np = style_image_np / 255.0\n",
        "\n",
        "# Converti l'array NumPy in un tensore TensorFlow\n",
        "style_image_tensor = tf.convert_to_tensor(style_image_np, dtype=tf.float32)\n",
        "\n",
        "# Aggiungi una dimensione batch all'inizio se necessario\n",
        "# Questo dipenderà dal tuo modello; alcuni modelli richiedono una dimensione batch\n",
        "style_image_tensor = tf.expand_dims(style_image_tensor, axis=0)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "iPQKuJMHF1XD",
        "outputId": "ce1d564f-f277-4a44-875e-55cc4126aa5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3fa6fd05-923e-4f76-9d23-b58e315f76df\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3fa6fd05-923e-4f76-9d23-b58e315f76df\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving anime.jpeg to anime (2).jpeg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class CustomStyleTransfer(Model):\n",
        "    def __init__(self, style_weight=1e-2, content_weight=1e-4):\n",
        "        super(CustomStyleTransfer, self).__init__()\n",
        "        self.style_weight = style_weight\n",
        "        self.content_weight = content_weight\n",
        "\n",
        "        # Utilizziamo la rete VGG19 pre-addestrata come estrattore di caratteristiche\n",
        "        vgg = VGG19(include_top=False, weights='imagenet')\n",
        "        vgg.trainable = False\n",
        "\n",
        "        # Selezioniamo gli strati specifici per il contenuto e lo stile\n",
        "        self.content_layers = ['block4_conv2']\n",
        "        self.style_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "\n",
        "        self.num_content_layers = len(self.content_layers)\n",
        "        self.num_style_layers = len(self.style_layers)\n",
        "\n",
        "        # Creiamo un modello che restituisce gli output di strati specifici\n",
        "        outputs = [vgg.get_layer(name).output for name in (self.content_layers + self.style_layers)]\n",
        "        self.vgg = Model(inputs=vgg.input, outputs=outputs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        content_image, style_image = inputs\n",
        "\n",
        "        # Preprocessa le immagini per VGG19\n",
        "        content_image = tf.keras.applications.vgg19.preprocess_input(content_image * 255)\n",
        "        style_image = tf.keras.applications.vgg19.preprocess_input(style_image * 255)\n",
        "\n",
        "        # Estrae le caratteristiche del contenuto e dello stile\n",
        "        content_outputs = self.vgg(content_image, training=False)\n",
        "        style_outputs = self.vgg(style_image, training=False)\n",
        "\n",
        "        content_dict = {name: value for name, value in zip(self.content_layers, content_outputs[:self.num_content_layers])}\n",
        "        style_dict = {name: value for name, value in zip(self.style_layers, style_outputs[self.num_content_layers:])}\n",
        "\n",
        "        # Calcola la perdita di contenuto\n",
        "        content_loss = tf.add_n([tf.reduce_mean((content_dict[name] - style_dict.get(name, tf.zeros_like(content_dict[name]))) ** 2)\n",
        "                         for name in self.content_layers])\n",
        "\n",
        "\n",
        "        content_loss *= self.content_weight / self.num_content_layers\n",
        "\n",
        "        # Calcola la perdita di stile\n",
        "        style_loss = tf.add_n([self.gram_matrix_loss(style_dict[name], style_dict[name])\n",
        "                       for name in self.style_layers])\n",
        "\n",
        "        style_loss *= self.style_weight / self.num_style_layers\n",
        "\n",
        "        # Combina le perdite di contenuto e stile\n",
        "        total_loss = content_loss + style_loss\n",
        "\n",
        "# Utilizza un ottimizzatore per minimizzare la perdita e generare l'immagine stilizzata\n",
        "        optimizer = tf.optimizers.Adam(learning_rate=0.02)\n",
        "\n",
        "# Definisci la variabile per l'immagine stilizzata, inizializzata con l'immagine di contenuto\n",
        "        stylized_image = tf.Variable(content_image)\n",
        "        return stylized_image\n",
        "\n",
        "\n",
        "\n",
        "    def get_content_features(self, image):\n",
        "        vgg_outputs = self.vgg(image, training=False)\n",
        "        content_dict = {layer.name: output for layer, output in zip(self.vgg.layers, vgg_outputs) if layer.name in self.content_layers}\n",
        "        return content_dict\n",
        "\n",
        "    def get_style_features(self, image):\n",
        "        vgg_outputs = self.vgg(image, training=False)\n",
        "        style_dict = {layer.name: output for layer, output in zip(self.vgg.layers, vgg_outputs) if layer.name in self.style_layers}\n",
        "        return style_dict\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Definisci una funzione di allenamento che esegue una singola iterazione di ottimizzazione\n",
        "    def train_step(self):\n",
        "      with tf.GradientTape() as tape:\n",
        "        # Calcola le perdite di contenuto e stile per l'immagine stilizzata corrente\n",
        "        style_output, content_output = self(stylized_image)\n",
        "        style_loss = self.compute_style_loss(style_output)\n",
        "        content_loss = self.compute_content_loss(content_output)\n",
        "        style_loss *= self.style_weight / self.num_style_layers\n",
        "        total_loss = content_loss + style_loss\n",
        "\n",
        "    # Calcola i gradienti\n",
        "      grads = tape.gradient(total_loss, stylized_image)\n",
        "\n",
        "    # Applica i gradienti per aggiornare l'immagine stilizzata\n",
        "      self.optimizer.apply_gradients([(grads, stylized_image)])\n",
        "\n",
        "\n",
        "    def train_model(self, num_iterations=10):  # Definisci un valore predefinito per num_iterations, se desiderato\n",
        "        for i in range(num_iterations):\n",
        "            self.train_step()\n",
        "\n",
        "\n",
        "    def gram_matrix_loss(self, style_output, content_output):\n",
        "    # Calcola la matrice di Gram per la perdita di stile\n",
        "      S_gram = self.gram_matrix(style_output)\n",
        "      C_gram = self.gram_matrix(content_output)\n",
        "      channels = tf.cast(style_output.shape[-1], tf.float32)  # Cast to float32\n",
        "      size = tf.cast(tf.size(style_output), tf.float32)  # Cast to float32\n",
        "      loss = tf.reduce_sum(tf.square(S_gram - C_gram)) / (4.0 * (channels ** 2) * (size ** 2))\n",
        "      return loss\n",
        "\n",
        "\n",
        "    def gram_matrix(self, input_tensor):\n",
        "    # La funzione gram_matrix calcola la matrice di Gram di un tensore di input\n",
        "    # Il tensore di input è ridimensionato a 2D (forma: channels, width*height) e trasposto\n",
        "      channels = input_tensor.shape[-1]\n",
        "      a = tf.reshape(input_tensor, [-1, channels])\n",
        "      n = tf.shape(a)[0]\n",
        "      gram = tf.matmul(a, a, transpose_a=True)\n",
        "      return gram / tf.cast(n, tf.float32)\n",
        "\n",
        "\n",
        "# Crea un'istanza del modello di trasferimento di stile personalizzato\n",
        "model = CustomStyleTransfer(style_weight=1e-2, content_weight=1e-4)\n",
        "model.train_model(num_iterations=500)\n",
        "\n",
        "output_fps = 30\n",
        "\n",
        "\n",
        "def resize_image(image, dimensions):\n",
        "    return tf.image.resize(image, dimensions)\n",
        "\n",
        "def load_image(image_path):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    image = image[tf.newaxis, :]\n",
        "    return image\n",
        "\n",
        "def tensor_to_image(tensor):\n",
        "    tensor = tensor * 255\n",
        "    tensor = np.array(tensor, dtype=np.uint8)\n",
        "    if np.ndim(tensor)>3:\n",
        "        assert tensor.shape[0] == 1\n",
        "        tensor = tensor[0]\n",
        "    return tensor\n",
        "\n",
        "def style_transfer(content_image, style_image):\n",
        "    # Nota: il tuo modello personalizzato non sembra avere un metodo call che restituisce un'immagine stilizzata direttamente.\n",
        "    # Potresti dover adattare questa funzione per lavorare con il tuo modello personalizzato.\n",
        "    stylized_image = model([tf.constant(content_image), tf.constant(style_image)])  # Modifica questa linea se necessario\n",
        "    return stylized_image  # Assicurati che questa funzione restituisca l'immagine stilizzata\n",
        "\n",
        "\n",
        "\n",
        "# Funzione per processare un frame del video\n",
        "def process_frame(frame):\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    frame_tensor = tf.convert_to_tensor(frame_rgb)\n",
        "    frame_tensor = tf.image.convert_image_dtype(frame_tensor, tf.float32)\n",
        "    frame_tensor = frame_tensor[tf.newaxis, :]\n",
        "    return frame_tensor\n",
        "\n",
        "\n",
        "writer = imageio.get_writer('styled_video.mp4', fps=output_fps)\n",
        "\n",
        "frame_count = 0\n",
        "start_time = time.time()\n",
        "\n",
        "style_image_resized = resize_image(style_image_tensor, (300, 300))\n",
        "\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Processa il frame\n",
        "    content_image = process_frame(frame)\n",
        "\n",
        "    content_image = resize_image(content_image, (300, 300))\n",
        "\n",
        "    # Esegui il trasferimento di stile\n",
        "    output = style_transfer(content_image, style_image_resized)\n",
        "\n",
        "    # Converte l'output in una immagine\n",
        "    output_frame_np = tensor_to_image(output)\n",
        "\n",
        "    # Scrivi il frame sul disco usando imageio\n",
        "    writer.append_data(output_frame_np)\n",
        "\n",
        "    # Aggiorna il contatore di frame\n",
        "    frame_count += 1\n",
        "\n",
        "    # Calcola e stampa i FPS ogni secondo\n",
        "    elapsed_time = time.time() - start_time\n",
        "    if elapsed_time > 1:\n",
        "        fps = frame_count / elapsed_time\n",
        "        print(f'FPS: {fps:.2f}')\n",
        "        # Resetta il contatore di frame e l'ora di inizio per il prossimo intervallo\n",
        "        frame_count = 0\n",
        "        start_time = time.time()\n",
        "\n",
        "# Rilascia le risorse\n",
        "cap.release()\n",
        "writer.close()\n",
        "\n",
        "# Scarica il video elaborato\n",
        "files.download('styled_video.mp4')\n"
      ],
      "metadata": {
        "id": "9foDh1I8GkzE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "ba6b5725-bf95-4fd4-cd02-1a9da319d60e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (300, 300) to (304, 304) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FPS: 4.54\n",
            "FPS: 12.35\n",
            "FPS: 16.74\n",
            "FPS: 16.78\n",
            "FPS: 15.93\n",
            "FPS: 15.88\n",
            "FPS: 16.47\n",
            "FPS: 15.81\n",
            "FPS: 16.34\n",
            "FPS: 16.38\n",
            "FPS: 16.21\n",
            "FPS: 15.91\n",
            "FPS: 11.47\n",
            "FPS: 10.59\n",
            "FPS: 10.57\n",
            "FPS: 14.66\n",
            "FPS: 16.61\n",
            "FPS: 15.91\n",
            "FPS: 15.72\n",
            "FPS: 16.01\n",
            "FPS: 16.06\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e2b4a84c-fdbe-42d0-ad48-9659a5c5d80c\", \"styled_video.mp4\", 5487710)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Carica il video\n",
        "uploaded = files.upload()\n",
        "video_name = list(uploaded.keys())[0]\n",
        "\n",
        "# Salva il video in una variabile\n",
        "video_data = uploaded[video_name]\n",
        "\n",
        "# Scrivi il video su disco temporaneamente per poterlo utilizzare con cv2\n",
        "with open(\"video.mp4\", \"wb\") as f:\n",
        "  f.write(video_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "_FuT1igJlGwh",
        "outputId": "f7acb7bc-7d48-4fd3-836e-257cf60f210a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-46666a27-31ca-4fd8-b99e-a3a6e3804173\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-46666a27-31ca-4fd8-b99e-a3a6e3804173\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving video.mp4 to video.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture('video.mp4')\n"
      ],
      "metadata": {
        "id": "SRrgQ1m-ms1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_hub as hub\n",
        "import cv2\n",
        "import numpy as np\n",
        "import imageio\n",
        "import time\n",
        "\n",
        "output_fps = 30\n",
        "\n",
        "\n",
        "def load_image(image_path):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    image = image[tf.newaxis, :]\n",
        "    return image\n",
        "\n",
        "def tensor_to_image(tensor):\n",
        "    tensor = tensor * 255\n",
        "    tensor = np.array(tensor, dtype=np.uint8)\n",
        "    if np.ndim(tensor)>3:\n",
        "        assert tensor.shape[0] == 1\n",
        "        tensor = tensor[0]\n",
        "    return tensor\n",
        "\n",
        "def style_transfer(content_image, style_image):\n",
        "    stylized_image = model(tf.constant(content_image), tf.constant(style_image))[0]\n",
        "    return stylized_image\n",
        "\n",
        "#def style_transfer(content_image, style_image):\n",
        "#    stylized_image = model(content_image, style_image)\n",
        "#    return stylized_image\n",
        "\n",
        "\n",
        "# Funzione per processare un frame del video\n",
        "def process_frame(frame):\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    frame_tensor = tf.convert_to_tensor(frame_rgb)\n",
        "    frame_tensor = tf.image.convert_image_dtype(frame_tensor, tf.float32)\n",
        "    frame_tensor = frame_tensor[tf.newaxis, :]\n",
        "    return frame_tensor\n",
        "\n",
        "\n",
        "writer = imageio.get_writer('styled_video.mp4', fps=output_fps)\n",
        "\n",
        "frame_count = 0\n",
        "start_time = time.time()\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Processa il frame\n",
        "    content_image = process_frame(frame)\n",
        "\n",
        "    # Esegui il trasferimento di stile\n",
        "    output = style_transfer(content_image, style_image_tensor)\n",
        "\n",
        "    # Converte l'output in una immagine\n",
        "    output_frame_np = tensor_to_image(output)\n",
        "\n",
        "    # Scrivi il frame sul disco usando imageio\n",
        "    writer.append_data(output_frame_np)\n",
        "\n",
        "    # Aggiorna il contatore di frame\n",
        "    frame_count += 1\n",
        "\n",
        "    # Calcola e stampa i FPS ogni secondo\n",
        "    elapsed_time = time.time() - start_time\n",
        "    if elapsed_time > 1:\n",
        "        fps = frame_count / elapsed_time\n",
        "        print(f'FPS: {fps:.2f}')\n",
        "        # Resetta il contatore di frame e l'ora di inizio per il prossimo intervallo\n",
        "        frame_count = 0\n",
        "        start_time = time.time()\n",
        "\n",
        "# Rilascia le risorse\n",
        "cap.release()\n",
        "writer.close()\n",
        "\n",
        "# Scarica il video elaborato\n",
        "files.download('styled_video.mp4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Dx4URYzvkGg4",
        "outputId": "9a5f1e67-bfcd-4059-cad6-9b28c2f48ec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FPS: 0.41\n",
            "FPS: 3.66\n",
            "FPS: 3.74\n",
            "FPS: 3.72\n",
            "FPS: 3.68\n",
            "FPS: 3.68\n",
            "FPS: 3.69\n",
            "FPS: 3.68\n",
            "FPS: 3.61\n",
            "FPS: 3.59\n",
            "FPS: 3.58\n",
            "FPS: 3.64\n",
            "FPS: 3.48\n",
            "FPS: 3.62\n",
            "FPS: 3.60\n",
            "FPS: 3.52\n",
            "FPS: 3.55\n",
            "FPS: 3.61\n",
            "FPS: 3.48\n",
            "FPS: 3.56\n",
            "FPS: 3.19\n",
            "FPS: 2.63\n",
            "FPS: 2.81\n",
            "FPS: 3.47\n",
            "FPS: 3.46\n",
            "FPS: 3.56\n",
            "FPS: 3.55\n",
            "FPS: 3.57\n",
            "FPS: 3.58\n",
            "FPS: 3.57\n",
            "FPS: 3.49\n",
            "FPS: 3.41\n",
            "FPS: 3.28\n",
            "FPS: 2.85\n",
            "FPS: 1.82\n",
            "FPS: 3.31\n",
            "FPS: 3.52\n",
            "FPS: 3.59\n",
            "FPS: 3.53\n",
            "FPS: 3.57\n",
            "FPS: 3.64\n",
            "FPS: 3.61\n",
            "FPS: 3.60\n",
            "FPS: 3.54\n",
            "FPS: 3.27\n",
            "FPS: 2.83\n",
            "FPS: 3.28\n",
            "FPS: 3.64\n",
            "FPS: 3.65\n",
            "FPS: 3.66\n",
            "FPS: 3.66\n",
            "FPS: 3.64\n",
            "FPS: 3.60\n",
            "FPS: 3.69\n",
            "FPS: 3.65\n",
            "FPS: 3.65\n",
            "FPS: 3.02\n",
            "FPS: 3.25\n",
            "FPS: 3.48\n",
            "FPS: 3.62\n",
            "FPS: 3.60\n",
            "FPS: 3.64\n",
            "FPS: 3.67\n",
            "FPS: 3.70\n",
            "FPS: 3.67\n",
            "FPS: 3.66\n",
            "FPS: 3.63\n",
            "FPS: 3.61\n",
            "FPS: 2.77\n",
            "FPS: 2.82\n",
            "FPS: 3.34\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_65d34ff0-df51-480f-a84b-a8d8d7056520\", \"styled_video.mp4\", 13709784)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "num_cores = os.cpu_count()\n",
        "print(f\"Numero di core della CPU: {num_cores}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvxJBYDK_vw7",
        "outputId": "33493de8-7baa-4e4a-c126-406abd378af5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numero di core della CPU: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(output))\n",
        "print(output)\n",
        "\n",
        "\n",
        "\n",
        "# Converti l'immagine PIL in un array NumPy\n",
        "output_array = np.array(output)\n",
        "\n",
        "# Converti l'array da RGB a BGR (formato OpenCV)\n",
        "output_frame = cv2.cvtColor(output_array, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "# Salva il frame elaborato\n",
        "out.write(output_frame)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "7RDdz4tu4XOC",
        "outputId": "6654c6ab-8e85-4722-cc5a-dba289720468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-85a7f7dbae6e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Salva il frame come immagine\n",
        "cv2.imwrite('output_frame.jpg', output_frame)\n",
        "\n",
        "# Scarica il file\n",
        "files.download('output_frame.jpg')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "Gp9NLKY77uDD",
        "outputId": "12578b63-7ac0-4e78-dc1c-dd1c1ed8c7d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-ad1b4eab30e8>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Salva il frame come immagine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output_frame.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Scarica il file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'output_frame' is not defined"
          ]
        }
      ]
    }
  ]
}